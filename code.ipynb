{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "SG-j84UEa7NP",
        "outputId": "e8fd3606-3d32-4a39-d136-4bec701f4d5e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'data/Data.zip'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-6c494278cf03>\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Download the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mdata_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://dicom5c.blob.core.windows.net/public/Data.zip'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mdownload_and_extract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Step 2: Load Data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-6c494278cf03>\u001b[0m in \u001b[0;36mdownload_and_extract\u001b[0;34m(url, extract_to)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mzip_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Data.zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/Data.zip'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.color import rgb2gray\n",
        "from skimage import exposure\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n",
        "import tensorflow as tf\n",
        "\n",
        "# Step 1: Download and extract the dataset\n",
        "def download_and_extract(url, extract_to='data'):\n",
        "    # Download the file\n",
        "    response = requests.get(url)\n",
        "    zip_file_path = os.path.join(extract_to, 'Data.zip')\n",
        "    with open(zip_file_path, 'wb') as f:\n",
        "        f.write(response.content)\n",
        "\n",
        "    # Extract the zip file\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "\n",
        "# Download the data\n",
        "data_url = 'https://dicom5c.blob.core.windows.net/public/Data.zip'\n",
        "download_and_extract(data_url)\n",
        "\n",
        "# Step 2: Load Data\n",
        "def load_data(data_path):\n",
        "    images = []\n",
        "    masks = []\n",
        "    for folder in os.listdir(data_path):\n",
        "        folder_path = os.path.join(data_path, folder)\n",
        "        if not os.path.isdir(folder_path):\n",
        "            continue\n",
        "        for file in os.listdir(folder_path):\n",
        "            if file.endswith('.tif'):  # Load only TIFF files\n",
        "                if 'mask' in file:\n",
        "                    mask = plt.imread(os.path.join(folder_path, file))\n",
        "                    masks.append(mask)\n",
        "                else:\n",
        "                    image = plt.imread(os.path.join(folder_path, file))\n",
        "                    # Convert image to grayscale if it has 3 channels\n",
        "                    if image.ndim == 3 and image.shape[2] == 3:  # RGB image\n",
        "                        image = rgb2gray(image)\n",
        "                    images.append(image)\n",
        "    return np.array(images), np.array(masks)\n",
        "\n",
        "# Load Dataset\n",
        "data_path = 'data/Data'  # Path to the extracted data folder\n",
        "images, masks = load_data(data_path)\n",
        "\n",
        "# Print sizes\n",
        "print(f'Total images found: {len(images)}')\n",
        "print(f'Total masks found: {len(masks)}')\n",
        "\n",
        "# Step 3: Preprocess Data\n",
        "def preprocess_data(images, masks):\n",
        "    # Apply CLAHE to images\n",
        "    clahe = exposure.equalize_adapthist(images, clip_limit=0.03)\n",
        "    images = clahe.reshape(images.shape)\n",
        "\n",
        "    # Normalize images and masks\n",
        "    images = images.astype(np.float32) / np.max(images)\n",
        "    masks = masks.astype(np.float32) / np.max(masks)\n",
        "\n",
        "    return images, masks\n",
        "\n",
        "# Preprocess data\n",
        "images, masks = preprocess_data(images, masks)\n",
        "\n",
        "# Split dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, masks, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define input shape\n",
        "input_shape = (X_train.shape[1], X_train.shape[2], 1)  # Grayscale images\n",
        "\n",
        "# Step 4: Define Nested U-Net Architecture\n",
        "def nested_unet(input_shape):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    # Encoder\n",
        "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
        "    p1 = MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
        "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "    # Bottleneck\n",
        "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
        "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
        "\n",
        "    # Decoder\n",
        "    u4 = UpSampling2D((2, 2))(c3)\n",
        "    u4 = concatenate([u4, c2])\n",
        "    c4 = Conv2D(128, (3, 3), activation='relu', padding='same')(u4)\n",
        "    c4 = Conv2D(128, (3, 3), activation='relu', padding='same')(c4)\n",
        "\n",
        "    u5 = UpSampling2D((2, 2))(c4)\n",
        "    u5 = concatenate([u5, c1])\n",
        "    c5 = Conv2D(64, (3, 3), activation='relu', padding='same')(u5)\n",
        "    c5 = Conv2D(64, (3, 3), activation='relu', padding='same')(c5)\n",
        "\n",
        "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c5)\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "    return model\n",
        "\n",
        "# Step 5: Train Nested U-Net\n",
        "nested_model = nested_unet(input_shape)\n",
        "nested_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "nested_history = nested_model.fit(X_train[..., np.newaxis], y_train[..., np.newaxis],\n",
        "                                   validation_data=(X_test[..., np.newaxis], y_test[..., np.newaxis]),\n",
        "                                   epochs=50, batch_size=16)\n",
        "\n",
        "# Step 6: Evaluate Model\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    # Calculate DICE score\n",
        "    predictions = model.predict(X_test)\n",
        "    predictions = (predictions > 0.5).astype(np.float32)  # Binarize predictions\n",
        "    dice_score = 2 * np.sum(predictions * y_test) / (np.sum(predictions) + np.sum(y_test) + 1e-6)\n",
        "    return dice_score\n",
        "\n",
        "average_dice = evaluate_model(nested_model, X_test[..., np.newaxis], y_test[..., np.newaxis])\n",
        "print(f'Average DICE Score: {average_dice:.4f}')\n",
        "\n",
        "# Step 7: Visualize Results\n",
        "def visualize_predictions(X_test, y_test, predictions, num_images=5):\n",
        "    for i in range(num_images):\n",
        "        plt.figure(figsize=(12, 4))\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.title(\"Original Image\")\n",
        "        plt.imshow(X_test[i], cmap='gray')\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.title(\"Ground Truth Mask\")\n",
        "        plt.imshow(y_test[i], cmap='gray')\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.title(\"Predicted Mask\")\n",
        "        plt.imshow(predictions[i, ..., 0], cmap='gray')\n",
        "        plt.show()\n",
        "\n",
        "predictions = nested_model.predict(X_test[..., np.newaxis])\n",
        "visualize_predictions(X_test, y_test, predictions)\n",
        "\n",
        "# Optional: Save the model\n",
        "nested_model.save('nested_unet_model.h5')\n"
      ]
    }
  ]
}